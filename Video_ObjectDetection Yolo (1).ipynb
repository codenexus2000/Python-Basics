{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f00ef69-27ca-4d6b-a278-907a8827cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.99-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\adi20\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Collecting numpy<=2.1.1,>=1.23.0 (from ultralytics)\n",
      "  Downloading numpy-2.1.1-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.21.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adi20\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Downloading ultralytics-8.3.99-py3-none-any.whl (976 kB)\n",
      "   ---------------------------------------- 0.0/976.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/976.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/976.9 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/976.9 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/976.9 kB ? eta -:--:--\n",
      "   -------------------- ----------------- 524.3/976.9 kB 672.2 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/976.9 kB 745.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 976.9/976.9 kB 775.2 kB/s eta 0:00:00\n",
      "Downloading numpy-2.1.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.6 MB 1.6 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 1.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 2.0 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.4/12.6 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.1/12.6 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.9/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.7/12.6 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.6/12.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.9/12.6 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 10.2/12.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.0/12.6 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 3.8 MB/s eta 0:00:00\n",
      "Using cached torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.21.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: sympy, numpy, torch, ultralytics-thop, torchvision, ultralytics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "Successfully installed numpy-2.1.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 ultralytics-8.3.99 ultralytics-thop-2.0.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.1 which is incompatible.\n",
      "inference-cli 0.43.0 requires numpy<=1.26.4, but you have numpy 2.1.1 which is incompatible.\n",
      "inference-cli 0.43.0 requires pillow<11.0,>=9.0.0, but you have pillow 11.1.0 which is incompatible.\n",
      "inference-sdk 0.43.0 requires numpy<=1.26.4, but you have numpy 2.1.1 which is incompatible.\n",
      "inference-sdk 0.43.0 requires pillow<11.0,>=9.0.0, but you have pillow 11.1.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.1 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.1.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.30.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba44caf-e1ac-4719-8210-a3245bbc9af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 7 persons, 2 trucks, 3 cows, 2 umbrellas, 129.3ms\n",
      "Speed: 3.5ms preprocess, 129.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 cow, 2 umbrellas, 125.6ms\n",
      "Speed: 3.1ms preprocess, 125.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 2 umbrellas, 112.5ms\n",
      "Speed: 2.3ms preprocess, 112.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 trucks, 2 umbrellas, 131.4ms\n",
      "Speed: 2.8ms preprocess, 131.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 2 umbrellas, 101.6ms\n",
      "Speed: 2.2ms preprocess, 101.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 100.7ms\n",
      "Speed: 1.8ms preprocess, 100.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 96.3ms\n",
      "Speed: 2.3ms preprocess, 96.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 1 umbrella, 94.5ms\n",
      "Speed: 1.8ms preprocess, 94.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 1 umbrella, 95.7ms\n",
      "Speed: 2.2ms preprocess, 95.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 1 umbrella, 103.7ms\n",
      "Speed: 1.9ms preprocess, 103.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 trucks, 2 cows, 1 umbrella, 89.3ms\n",
      "Speed: 1.9ms preprocess, 89.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 1 umbrella, 85.1ms\n",
      "Speed: 2.0ms preprocess, 85.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 trucks, 1 cow, 3 umbrellas, 91.5ms\n",
      "Speed: 2.0ms preprocess, 91.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 trucks, 1 cow, 3 umbrellas, 86.1ms\n",
      "Speed: 2.1ms preprocess, 86.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 cow, 3 umbrellas, 83.9ms\n",
      "Speed: 2.8ms preprocess, 83.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 trucks, 3 umbrellas, 82.8ms\n",
      "Speed: 1.8ms preprocess, 82.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 trucks, 3 umbrellas, 101.7ms\n",
      "Speed: 2.1ms preprocess, 101.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 3 umbrellas, 95.6ms\n",
      "Speed: 2.0ms preprocess, 95.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 trucks, 4 umbrellas, 91.1ms\n",
      "Speed: 2.5ms preprocess, 91.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 trucks, 4 umbrellas, 93.5ms\n",
      "Speed: 1.8ms preprocess, 93.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 trucks, 3 cows, 3 umbrellas, 90.2ms\n",
      "Speed: 1.7ms preprocess, 90.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 95.3ms\n",
      "Speed: 1.9ms preprocess, 95.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bus, 2 trucks, 1 umbrella, 89.0ms\n",
      "Speed: 1.7ms preprocess, 89.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 4 cows, 1 umbrella, 106.3ms\n",
      "Speed: 1.8ms preprocess, 106.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 1 umbrella, 93.9ms\n",
      "Speed: 1.4ms preprocess, 93.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 cow, 1 umbrella, 99.2ms\n",
      "Speed: 2.0ms preprocess, 99.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bus, 2 trucks, 2 cows, 2 umbrellas, 93.1ms\n",
      "Speed: 1.8ms preprocess, 93.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 3 cows, 94.0ms\n",
      "Speed: 1.8ms preprocess, 94.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 2 trucks, 1 cow, 92.4ms\n",
      "Speed: 1.8ms preprocess, 92.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 2 trucks, 1 cow, 1 umbrella, 92.8ms\n",
      "Speed: 1.9ms preprocess, 92.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 2 trucks, 1 dog, 2 umbrellas, 100.8ms\n",
      "Speed: 1.8ms preprocess, 100.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 trucks, 98.9ms\n",
      "Speed: 2.9ms preprocess, 98.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 buss, 3 trucks, 1 dog, 93.7ms\n",
      "Speed: 2.0ms preprocess, 93.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bus, 2 trucks, 151.1ms\n",
      "Speed: 1.9ms preprocess, 151.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 71.8ms\n",
      "Speed: 1.9ms preprocess, 71.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 2 trucks, 1 dog, 1 frisbee, 94.0ms\n",
      "Speed: 1.9ms preprocess, 94.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 2 trucks, 1 dog, 1 frisbee, 90.1ms\n",
      "Speed: 2.2ms preprocess, 90.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 1 truck, 1 dog, 75.5ms\n",
      "Speed: 2.3ms preprocess, 75.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 70.0ms\n",
      "Speed: 1.6ms preprocess, 70.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 dog, 1 frisbee, 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 1 dog, 1 frisbee, 73.7ms\n",
      "Speed: 2.1ms preprocess, 73.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 dog, 66.9ms\n",
      "Speed: 2.8ms preprocess, 66.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 dog, 1 umbrella, 72.5ms\n",
      "Speed: 1.9ms preprocess, 72.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 1 dog, 1 umbrella, 68.7ms\n",
      "Speed: 1.6ms preprocess, 68.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 dog, 1 cow, 71.7ms\n",
      "Speed: 1.5ms preprocess, 71.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 dog, 1 horse, 1 umbrella, 65.4ms\n",
      "Speed: 1.8ms preprocess, 65.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 truck, 1 dog, 1 horse, 1 umbrella, 74.9ms\n",
      "Speed: 1.8ms preprocess, 74.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 horse, 1 umbrella, 71.6ms\n",
      "Speed: 2.0ms preprocess, 71.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 bus, 1 truck, 1 dog, 1 cow, 2 umbrellas, 67.1ms\n",
      "Speed: 2.0ms preprocess, 67.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 truck, 1 dog, 1 horse, 1 cow, 1 umbrella, 69.3ms\n",
      "Speed: 1.8ms preprocess, 69.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 bus, 1 truck, 1 horse, 1 umbrella, 63.1ms\n",
      "Speed: 1.6ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 truck, 1 horse, 1 cow, 1 umbrella, 1 frisbee, 66.3ms\n",
      "Speed: 1.5ms preprocess, 66.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 cow, 1 umbrella, 65.5ms\n",
      "Speed: 1.7ms preprocess, 65.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 1 umbrella, 1 frisbee, 68.5ms\n",
      "Speed: 1.8ms preprocess, 68.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 1 frisbee, 63.7ms\n",
      "Speed: 1.9ms preprocess, 63.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 1 truck, 1 dog, 1 cow, 1 frisbee, 64.6ms\n",
      "Speed: 1.6ms preprocess, 64.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 frisbee, 76.8ms\n",
      "Speed: 1.8ms preprocess, 76.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 truck, 1 dog, 1 cow, 1 frisbee, 71.3ms\n",
      "Speed: 1.6ms preprocess, 71.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 truck, 1 dog, 1 cow, 1 frisbee, 69.8ms\n",
      "Speed: 1.9ms preprocess, 69.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 umbrella, 1 frisbee, 72.8ms\n",
      "Speed: 1.8ms preprocess, 72.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 handbag, 1 frisbee, 61.8ms\n",
      "Speed: 1.7ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 handbag, 63.8ms\n",
      "Speed: 1.5ms preprocess, 63.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 handbag, 58.0ms\n",
      "Speed: 1.2ms preprocess, 58.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 dog, 1 cow, 1 handbag, 1 frisbee, 59.1ms\n",
      "Speed: 1.4ms preprocess, 59.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 dog, 1 cow, 1 handbag, 122.7ms\n",
      "Speed: 1.5ms preprocess, 122.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 dog, 1 cow, 1 umbrella, 104.4ms\n",
      "Speed: 2.0ms preprocess, 104.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 2 umbrellas, 109.5ms\n",
      "Speed: 2.7ms preprocess, 109.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 truck, 1 dog, 1 cow, 93.2ms\n",
      "Speed: 2.8ms preprocess, 93.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 90.1ms\n",
      "Speed: 2.6ms preprocess, 90.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 84.3ms\n",
      "Speed: 2.1ms preprocess, 84.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 cow, 78.7ms\n",
      "Speed: 2.2ms preprocess, 78.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bus, 2 trucks, 1 cow, 89.2ms\n",
      "Speed: 1.9ms preprocess, 89.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 cow, 103.9ms\n",
      "Speed: 2.1ms preprocess, 103.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 truck, 1 cow, 84.6ms\n",
      "Speed: 1.9ms preprocess, 84.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 cow, 73.5ms\n",
      "Speed: 2.2ms preprocess, 73.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 dog, 1 cow, 74.7ms\n",
      "Speed: 2.0ms preprocess, 74.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 trucks, 1 dog, 70.5ms\n",
      "Speed: 2.2ms preprocess, 70.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 dog, 70.6ms\n",
      "Speed: 1.7ms preprocess, 70.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 1 dog, 61.0ms\n",
      "Speed: 1.5ms preprocess, 61.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 1 dog, 62.7ms\n",
      "Speed: 1.8ms preprocess, 62.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 1 dog, 1 backpack, 63.6ms\n",
      "Speed: 2.0ms preprocess, 63.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 1 dog, 1 handbag, 63.4ms\n",
      "Speed: 1.7ms preprocess, 63.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 trucks, 1 dog, 1 handbag, 76.4ms\n",
      "Speed: 1.4ms preprocess, 76.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 truck, 1 dog, 65.7ms\n",
      "Speed: 1.6ms preprocess, 65.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 trucks, 1 dog, 1 handbag, 63.5ms\n",
      "Speed: 1.6ms preprocess, 63.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 truck, 1 dog, 1 handbag, 58.8ms\n",
      "Speed: 1.3ms preprocess, 58.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 truck, 1 dog, 1 handbag, 59.7ms\n",
      "Speed: 1.5ms preprocess, 59.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 trucks, 1 dog, 1 handbag, 66.7ms\n",
      "Speed: 1.4ms preprocess, 66.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 trucks, 1 handbag, 69.2ms\n",
      "Speed: 1.5ms preprocess, 69.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 72.3ms\n",
      "Speed: 1.5ms preprocess, 72.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bus, 1 truck, 1 dog, 1 cow, 68.6ms\n",
      "Speed: 1.4ms preprocess, 68.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 bus, 1 truck, 1 dog, 1 horse, 74.9ms\n",
      "Speed: 1.4ms preprocess, 74.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 horse, 84.0ms\n",
      "Speed: 1.4ms preprocess, 84.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 1 truck, 1 horse, 1 cow, 1 handbag, 1 frisbee, 74.0ms\n",
      "Speed: 1.9ms preprocess, 74.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 1 truck, 1 horse, 1 cow, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 dog, 1 horse, 1 cow, 73.6ms\n",
      "Speed: 1.7ms preprocess, 73.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 1 truck, 1 horse, 1 cow, 70.5ms\n",
      "Speed: 1.5ms preprocess, 70.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 horse, 70.6ms\n",
      "Speed: 2.1ms preprocess, 70.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 horse, 1 cow, 72.3ms\n",
      "Speed: 1.8ms preprocess, 72.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 dog, 1 cow, 1 umbrella, 1 frisbee, 79.1ms\n",
      "Speed: 1.7ms preprocess, 79.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 dog, 1 horse, 1 cow, 1 frisbee, 80.8ms\n",
      "Speed: 2.1ms preprocess, 80.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 dog, 1 cow, 1 frisbee, 75.9ms\n",
      "Speed: 1.7ms preprocess, 75.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 cow, 1 frisbee, 77.6ms\n",
      "Speed: 1.5ms preprocess, 77.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 cow, 1 frisbee, 88.7ms\n",
      "Speed: 1.8ms preprocess, 88.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 2 cows, 1 frisbee, 77.4ms\n",
      "Speed: 2.0ms preprocess, 77.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 2 trucks, 1 dog, 2 cows, 1 frisbee, 74.1ms\n",
      "Speed: 1.6ms preprocess, 74.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 2 cows, 1 frisbee, 73.2ms\n",
      "Speed: 1.8ms preprocess, 73.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 traffic light, 2 cows, 73.5ms\n",
      "Speed: 1.5ms preprocess, 73.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 traffic light, 3 cows, 1 frisbee, 69.7ms\n",
      "Speed: 1.7ms preprocess, 69.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 traffic light, 2 cows, 1 umbrella, 63.5ms\n",
      "Speed: 1.3ms preprocess, 63.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bus, 1 truck, 1 traffic light, 2 cows, 1 umbrella, 63.1ms\n",
      "Speed: 1.8ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bus, 1 truck, 1 cow, 1 umbrella, 66.3ms\n",
      "Speed: 1.7ms preprocess, 66.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 1 truck, 1 cow, 1 umbrella, 70.1ms\n",
      "Speed: 1.9ms preprocess, 70.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 trucks, 2 cows, 1 umbrella, 65.0ms\n",
      "Speed: 1.8ms preprocess, 65.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 cow, 1 umbrella, 87.5ms\n",
      "Speed: 2.3ms preprocess, 87.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 cow, 1 umbrella, 66.4ms\n",
      "Speed: 1.7ms preprocess, 66.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 3 cows, 1 umbrella, 70.5ms\n",
      "Speed: 1.9ms preprocess, 70.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 3 cows, 69.8ms\n",
      "Speed: 2.0ms preprocess, 69.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 3 cows, 1 umbrella, 69.5ms\n",
      "Speed: 1.5ms preprocess, 69.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 3 cows, 67.0ms\n",
      "Speed: 2.2ms preprocess, 67.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 3 cows, 60.2ms\n",
      "Speed: 1.6ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 cow, 101.8ms\n",
      "Speed: 1.6ms preprocess, 101.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 cow, 1 umbrella, 69.6ms\n",
      "Speed: 2.6ms preprocess, 69.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 buss, 1 truck, 1 cow, 1 umbrella, 71.4ms\n",
      "Speed: 1.4ms preprocess, 71.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 2 buss, 1 truck, 1 dog, 66.7ms\n",
      "Speed: 1.8ms preprocess, 66.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 1 cat, 1 umbrella, 63.6ms\n",
      "Speed: 1.7ms preprocess, 63.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 umbrella, 106.8ms\n",
      "Speed: 1.7ms preprocess, 106.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 1 umbrella, 97.4ms\n",
      "Speed: 2.5ms preprocess, 97.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 umbrella, 68.6ms\n",
      "Speed: 1.6ms preprocess, 68.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 umbrella, 83.8ms\n",
      "Speed: 2.4ms preprocess, 83.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 buss, 1 truck, 74.2ms\n",
      "Speed: 1.4ms preprocess, 74.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 motorcycle, 2 buss, 1 truck, 71.9ms\n",
      "Speed: 2.1ms preprocess, 71.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 67.1ms\n",
      "Speed: 1.7ms preprocess, 67.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 car, 1 motorcycle, 2 buss, 1 truck, 64.6ms\n",
      "Speed: 1.6ms preprocess, 64.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 motorcycle, 2 buss, 1 truck, 1 traffic light, 66.0ms\n",
      "Speed: 1.5ms preprocess, 66.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Speed: 2.5ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.9ms\n",
      "Speed: 1.4ms preprocess, 85.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.8ms\n",
      "Speed: 1.6ms preprocess, 72.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 69.7ms\n",
      "Speed: 1.8ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.5ms\n",
      "Speed: 2.0ms preprocess, 63.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.5ms\n",
      "Speed: 1.4ms preprocess, 63.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.6ms\n",
      "Speed: 1.8ms preprocess, 62.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 60.2ms\n",
      "Speed: 1.4ms preprocess, 60.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.2ms\n",
      "Speed: 1.7ms preprocess, 84.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.4ms\n",
      "Speed: 1.9ms preprocess, 70.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.6ms\n",
      "Speed: 2.0ms preprocess, 62.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.2ms\n",
      "Speed: 1.6ms preprocess, 67.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.7ms\n",
      "Speed: 1.8ms preprocess, 81.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.0ms\n",
      "Speed: 1.5ms preprocess, 84.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 81.9ms\n",
      "Speed: 1.9ms preprocess, 81.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 80.7ms\n",
      "Speed: 2.5ms preprocess, 80.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 75.8ms\n",
      "Speed: 1.9ms preprocess, 75.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 98.8ms\n",
      "Speed: 2.0ms preprocess, 98.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 81.8ms\n",
      "Speed: 2.0ms preprocess, 81.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 80.0ms\n",
      "Speed: 2.1ms preprocess, 80.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 microwave, 81.6ms\n",
      "Speed: 1.8ms preprocess, 81.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 microwave, 80.1ms\n",
      "Speed: 2.0ms preprocess, 80.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 microwave, 73.5ms\n",
      "Speed: 2.3ms preprocess, 73.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 72.4ms\n",
      "Speed: 1.5ms preprocess, 72.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 73.4ms\n",
      "Speed: 2.0ms preprocess, 73.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 70.1ms\n",
      "Speed: 2.2ms preprocess, 70.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 83.1ms\n",
      "Speed: 2.1ms preprocess, 83.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.6ms\n",
      "Speed: 1.8ms preprocess, 72.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 microwave, 70.9ms\n",
      "Speed: 1.7ms preprocess, 70.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 68.3ms\n",
      "Speed: 1.8ms preprocess, 68.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 microwave, 1 book, 69.1ms\n",
      "Speed: 1.6ms preprocess, 69.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 71.5ms\n",
      "Speed: 1.9ms preprocess, 71.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 microwave, 1 book, 75.5ms\n",
      "Speed: 2.0ms preprocess, 75.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 70.2ms\n",
      "Speed: 1.5ms preprocess, 70.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 76.0ms\n",
      "Speed: 1.4ms preprocess, 76.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 73.5ms\n",
      "Speed: 1.9ms preprocess, 73.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 69.8ms\n",
      "Speed: 1.9ms preprocess, 69.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 68.3ms\n",
      "Speed: 1.6ms preprocess, 68.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 68.6ms\n",
      "Speed: 1.5ms preprocess, 68.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 69.6ms\n",
      "Speed: 1.7ms preprocess, 69.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 76.4ms\n",
      "Speed: 1.7ms preprocess, 76.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 68.0ms\n",
      "Speed: 1.9ms preprocess, 68.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 100.8ms\n",
      "Speed: 1.6ms preprocess, 100.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 143.9ms\n",
      "Speed: 3.6ms preprocess, 143.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 77.1ms\n",
      "Speed: 2.0ms preprocess, 77.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.3ms\n",
      "Speed: 1.5ms preprocess, 73.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 73.1ms\n",
      "Speed: 2.1ms preprocess, 73.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 72.8ms\n",
      "Speed: 1.4ms preprocess, 72.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 71.3ms\n",
      "Speed: 2.3ms preprocess, 71.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 70.7ms\n",
      "Speed: 2.1ms preprocess, 70.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 book, 74.8ms\n",
      "Speed: 1.9ms preprocess, 74.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 82.1ms\n",
      "Speed: 2.0ms preprocess, 82.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 70.5ms\n",
      "Speed: 1.4ms preprocess, 70.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 82.0ms\n",
      "Speed: 1.5ms preprocess, 82.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 72.4ms\n",
      "Speed: 2.1ms preprocess, 72.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 71.5ms\n",
      "Speed: 1.8ms preprocess, 71.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 72.1ms\n",
      "Speed: 1.7ms preprocess, 72.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 72.0ms\n",
      "Speed: 1.7ms preprocess, 72.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 book, 68.1ms\n",
      "Speed: 2.0ms preprocess, 68.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 82.2ms\n",
      "Speed: 1.6ms preprocess, 82.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 73.7ms\n",
      "Speed: 1.8ms preprocess, 73.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.4ms\n",
      "Speed: 1.6ms preprocess, 73.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 75.9ms\n",
      "Speed: 1.8ms preprocess, 75.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.0ms\n",
      "Speed: 1.6ms preprocess, 72.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 2.3ms preprocess, 76.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.2ms\n",
      "Speed: 1.7ms preprocess, 73.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 76.3ms\n",
      "Speed: 1.7ms preprocess, 76.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.8ms\n",
      "Speed: 1.8ms preprocess, 71.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 86.8ms\n",
      "Speed: 1.6ms preprocess, 86.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 77.5ms\n",
      "Speed: 1.8ms preprocess, 77.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 74.8ms\n",
      "Speed: 2.2ms preprocess, 74.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 75.6ms\n",
      "Speed: 2.2ms preprocess, 75.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 1.8ms preprocess, 72.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.0ms\n",
      "Speed: 1.7ms preprocess, 74.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.6ms\n",
      "Speed: 2.9ms preprocess, 94.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.5ms\n",
      "Speed: 1.8ms preprocess, 84.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.4ms\n",
      "Speed: 1.8ms preprocess, 100.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.2ms\n",
      "Speed: 4.0ms preprocess, 99.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.3ms\n",
      "Speed: 1.9ms preprocess, 83.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 93.1ms\n",
      "Speed: 2.0ms preprocess, 93.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 84.2ms\n",
      "Speed: 1.9ms preprocess, 84.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 92.3ms\n",
      "Speed: 1.8ms preprocess, 92.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 148.0ms\n",
      "Speed: 3.8ms preprocess, 148.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 90.2ms\n",
      "Speed: 1.9ms preprocess, 90.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 81.8ms\n",
      "Speed: 2.5ms preprocess, 81.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.9ms\n",
      "Speed: 1.8ms preprocess, 82.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.6ms\n",
      "Speed: 1.9ms preprocess, 94.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.1ms\n",
      "Speed: 1.6ms preprocess, 75.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 68.8ms\n",
      "Speed: 1.7ms preprocess, 68.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 79.3ms\n",
      "Speed: 1.7ms preprocess, 79.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 78.9ms\n",
      "Speed: 1.9ms preprocess, 78.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 71.8ms\n",
      "Speed: 2.5ms preprocess, 71.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 1.6ms preprocess, 71.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.9ms\n",
      "Speed: 1.7ms preprocess, 66.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.6ms\n",
      "Speed: 1.7ms preprocess, 65.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.4ms\n",
      "Speed: 1.8ms preprocess, 70.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.0ms\n",
      "Speed: 1.7ms preprocess, 92.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.2ms\n",
      "Speed: 2.2ms preprocess, 73.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.7ms\n",
      "Speed: 1.6ms preprocess, 72.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.7ms\n",
      "Speed: 1.5ms preprocess, 70.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.7ms\n",
      "Speed: 1.4ms preprocess, 72.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 1.8ms preprocess, 72.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.1ms\n",
      "Speed: 1.7ms preprocess, 78.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.5ms\n",
      "Speed: 1.4ms preprocess, 78.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.3ms\n",
      "Speed: 1.4ms preprocess, 69.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.3ms\n",
      "Speed: 1.6ms preprocess, 89.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.3ms\n",
      "Speed: 2.2ms preprocess, 72.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.0ms\n",
      "Speed: 1.9ms preprocess, 72.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.0ms\n",
      "Speed: 1.9ms preprocess, 68.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.3ms\n",
      "Speed: 1.6ms preprocess, 62.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.4ms\n",
      "Speed: 1.4ms preprocess, 63.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.4ms\n",
      "Speed: 1.2ms preprocess, 66.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.8ms\n",
      "Speed: 1.9ms preprocess, 63.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.5ms\n",
      "Speed: 1.5ms preprocess, 64.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.0ms\n",
      "Speed: 1.4ms preprocess, 76.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 63.0ms\n",
      "Speed: 1.9ms preprocess, 63.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.9ms\n",
      "Speed: 1.5ms preprocess, 65.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 139.6ms\n",
      "Speed: 3.1ms preprocess, 139.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.5ms\n",
      "Speed: 3.4ms preprocess, 71.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.6ms\n",
      "Speed: 1.8ms preprocess, 63.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.9ms\n",
      "Speed: 1.5ms preprocess, 62.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 65.1ms\n",
      "Speed: 1.4ms preprocess, 65.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 62.9ms\n",
      "Speed: 1.2ms preprocess, 62.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 63.5ms\n",
      "Speed: 1.6ms preprocess, 63.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 75.6ms\n",
      "Speed: 2.1ms preprocess, 75.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 66.0ms\n",
      "Speed: 1.3ms preprocess, 66.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 65.6ms\n",
      "Speed: 1.4ms preprocess, 65.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 61.5ms\n",
      "Speed: 1.6ms preprocess, 61.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 62.2ms\n",
      "Speed: 1.5ms preprocess, 62.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Speed: 1.4ms preprocess, 66.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.8ms\n",
      "Speed: 1.7ms preprocess, 63.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 61.0ms\n",
      "Speed: 1.6ms preprocess, 61.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 64.2ms\n",
      "Speed: 2.0ms preprocess, 64.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 toothbrush, 64.9ms\n",
      "Speed: 1.6ms preprocess, 64.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 toothbrush, 64.2ms\n",
      "Speed: 1.5ms preprocess, 64.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 81.9ms\n",
      "Speed: 1.6ms preprocess, 81.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 63.8ms\n",
      "Speed: 2.2ms preprocess, 63.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 67.9ms\n",
      "Speed: 1.5ms preprocess, 67.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 65.3ms\n",
      "Speed: 1.6ms preprocess, 65.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 66.1ms\n",
      "Speed: 1.3ms preprocess, 66.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 65.4ms\n",
      "Speed: 1.4ms preprocess, 65.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.6ms\n",
      "Speed: 1.4ms preprocess, 63.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.0ms\n",
      "Speed: 1.7ms preprocess, 78.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.0ms\n",
      "Speed: 2.5ms preprocess, 68.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.3ms\n",
      "Speed: 1.9ms preprocess, 64.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.8ms\n",
      "Speed: 1.4ms preprocess, 64.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 1.6ms preprocess, 64.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.0ms\n",
      "Speed: 1.8ms preprocess, 92.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 126.5ms\n",
      "Speed: 6.4ms preprocess, 126.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.2ms\n",
      "Speed: 1.8ms preprocess, 96.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.2ms\n",
      "Speed: 1.4ms preprocess, 83.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.8ms\n",
      "Speed: 1.5ms preprocess, 65.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.9ms\n",
      "Speed: 1.4ms preprocess, 68.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.4ms\n",
      "Speed: 2.2ms preprocess, 66.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.6ms\n",
      "Speed: 1.3ms preprocess, 61.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.7ms\n",
      "Speed: 1.7ms preprocess, 62.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 1.5ms preprocess, 66.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.7ms\n",
      "Speed: 1.5ms preprocess, 59.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.2ms\n",
      "Speed: 1.5ms preprocess, 89.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.9ms\n",
      "Speed: 2.1ms preprocess, 69.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.7ms\n",
      "Speed: 1.4ms preprocess, 63.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 69.2ms\n",
      "Speed: 1.4ms preprocess, 69.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 64.1ms\n",
      "Speed: 1.4ms preprocess, 64.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 65.3ms\n",
      "Speed: 2.0ms preprocess, 65.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 63.5ms\n",
      "Speed: 2.0ms preprocess, 63.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.2ms\n",
      "Speed: 1.6ms preprocess, 69.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.5ms\n",
      "Speed: 2.2ms preprocess, 86.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.7ms\n",
      "Speed: 1.4ms preprocess, 67.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.2ms\n",
      "Speed: 1.5ms preprocess, 65.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.6ms\n",
      "Speed: 1.5ms preprocess, 71.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 toothbrush, 62.9ms\n",
      "Speed: 1.6ms preprocess, 62.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.9ms\n",
      "Speed: 1.6ms preprocess, 61.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.1ms\n",
      "Speed: 2.8ms preprocess, 65.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.7ms\n",
      "Speed: 1.8ms preprocess, 84.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.1ms\n",
      "Speed: 2.6ms preprocess, 74.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 152.0ms\n",
      "Speed: 5.3ms preprocess, 152.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.9ms\n",
      "Speed: 1.6ms preprocess, 78.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.5ms\n",
      "Speed: 1.8ms preprocess, 62.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.6ms\n",
      "Speed: 2.3ms preprocess, 70.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.5ms\n",
      "Speed: 2.0ms preprocess, 73.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.6ms\n",
      "Speed: 2.4ms preprocess, 70.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.4ms\n",
      "Speed: 1.8ms preprocess, 71.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.8ms\n",
      "Speed: 1.6ms preprocess, 77.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.1ms\n",
      "Speed: 2.4ms preprocess, 83.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.8ms\n",
      "Speed: 2.0ms preprocess, 78.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.1ms\n",
      "Speed: 1.9ms preprocess, 81.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.6ms\n",
      "Speed: 3.2ms preprocess, 93.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.4ms\n",
      "Speed: 2.2ms preprocess, 81.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.6ms\n",
      "Speed: 2.6ms preprocess, 89.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.1ms\n",
      "Speed: 1.9ms preprocess, 81.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.1ms\n",
      "Speed: 2.9ms preprocess, 76.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.9ms\n",
      "Speed: 1.8ms preprocess, 76.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.7ms\n",
      "Speed: 1.8ms preprocess, 73.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 73.5ms\n",
      "Speed: 2.2ms preprocess, 73.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.0ms\n",
      "Speed: 1.7ms preprocess, 71.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.2ms\n",
      "Speed: 1.9ms preprocess, 73.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.0ms\n",
      "Speed: 1.9ms preprocess, 77.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.2ms\n",
      "Speed: 1.8ms preprocess, 74.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.7ms\n",
      "Speed: 2.0ms preprocess, 74.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.8ms\n",
      "Speed: 2.1ms preprocess, 76.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 174.1ms\n",
      "Speed: 6.2ms preprocess, 174.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.4ms\n",
      "Speed: 3.7ms preprocess, 88.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.5ms\n",
      "Speed: 1.9ms preprocess, 97.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.7ms\n",
      "Speed: 2.2ms preprocess, 76.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.3ms\n",
      "Speed: 1.7ms preprocess, 80.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.3ms\n",
      "Speed: 2.2ms preprocess, 73.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.5ms\n",
      "Speed: 2.0ms preprocess, 74.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.1ms\n",
      "Speed: 1.6ms preprocess, 76.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.7ms\n",
      "Speed: 1.6ms preprocess, 71.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 1.4ms preprocess, 76.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.0ms\n",
      "Speed: 2.1ms preprocess, 75.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.6ms\n",
      "Speed: 2.2ms preprocess, 87.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 75.1ms\n",
      "Speed: 2.1ms preprocess, 75.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.8ms\n",
      "Speed: 1.9ms preprocess, 72.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.8ms\n",
      "Speed: 1.6ms preprocess, 72.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.2ms\n",
      "Speed: 1.5ms preprocess, 76.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.5ms\n",
      "Speed: 1.7ms preprocess, 78.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.2ms\n",
      "Speed: 1.6ms preprocess, 71.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.6ms\n",
      "Speed: 1.8ms preprocess, 75.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 1.9ms preprocess, 76.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.2ms\n",
      "Speed: 1.7ms preprocess, 74.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.5ms\n",
      "Speed: 2.2ms preprocess, 92.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.7ms\n",
      "Speed: 1.6ms preprocess, 75.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.9ms\n",
      "Speed: 2.1ms preprocess, 96.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.7ms\n",
      "Speed: 2.3ms preprocess, 82.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Speed: 1.7ms preprocess, 76.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 171.3ms\n",
      "Speed: 3.8ms preprocess, 171.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.3ms\n",
      "Speed: 2.7ms preprocess, 83.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 67.5ms\n",
      "Speed: 1.5ms preprocess, 67.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 66.4ms\n",
      "Speed: 1.6ms preprocess, 66.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 77.8ms\n",
      "Speed: 2.2ms preprocess, 77.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.0ms\n",
      "Speed: 1.7ms preprocess, 75.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 68.0ms\n",
      "Speed: 1.6ms preprocess, 68.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 69.8ms\n",
      "Speed: 1.8ms preprocess, 69.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 72.7ms\n",
      "Speed: 1.7ms preprocess, 72.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 64.2ms\n",
      "Speed: 1.5ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 68.7ms\n",
      "Speed: 1.8ms preprocess, 68.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 76.7ms\n",
      "Speed: 1.8ms preprocess, 76.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 73.1ms\n",
      "Speed: 1.6ms preprocess, 73.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 74.3ms\n",
      "Speed: 1.6ms preprocess, 74.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 71.3ms\n",
      "Speed: 2.2ms preprocess, 71.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 book, 72.0ms\n",
      "Speed: 1.8ms preprocess, 72.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 book, 71.5ms\n",
      "Speed: 1.6ms preprocess, 71.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 65.2ms\n",
      "Speed: 1.5ms preprocess, 65.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 72.2ms\n",
      "Speed: 1.8ms preprocess, 72.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 77.0ms\n",
      "Speed: 1.6ms preprocess, 77.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 67.4ms\n",
      "Speed: 1.6ms preprocess, 67.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 1 laptop, 117.6ms\n",
      "Speed: 1.5ms preprocess, 117.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 100.7ms\n",
      "Speed: 2.8ms preprocess, 100.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 laptops, 83.4ms\n",
      "Speed: 6.3ms preprocess, 83.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 66.0ms\n",
      "Speed: 1.5ms preprocess, 66.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 68.9ms\n",
      "Speed: 2.2ms preprocess, 68.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 wine glass, 1 laptop, 73.9ms\n",
      "Speed: 1.7ms preprocess, 73.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 71.8ms\n",
      "Speed: 1.6ms preprocess, 71.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 73.5ms\n",
      "Speed: 1.7ms preprocess, 73.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 66.4ms\n",
      "Speed: 1.4ms preprocess, 66.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.2ms\n",
      "Speed: 2.0ms preprocess, 69.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 73.6ms\n",
      "Speed: 1.5ms preprocess, 73.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 88.3ms\n",
      "Speed: 1.8ms preprocess, 88.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 66.8ms\n",
      "Speed: 1.6ms preprocess, 66.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 64.1ms\n",
      "Speed: 1.9ms preprocess, 64.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 67.8ms\n",
      "Speed: 2.0ms preprocess, 67.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 69.5ms\n",
      "Speed: 1.6ms preprocess, 69.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 70.9ms\n",
      "Speed: 1.4ms preprocess, 70.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 books, 63.2ms\n",
      "Speed: 1.9ms preprocess, 63.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 books, 65.2ms\n",
      "Speed: 1.6ms preprocess, 65.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 3 books, 65.1ms\n",
      "Speed: 1.6ms preprocess, 65.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 bottles, 66.6ms\n",
      "Speed: 1.8ms preprocess, 66.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3 bottles, 170.8ms\n",
      "Speed: 9.9ms preprocess, 170.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6 bottles, 82.6ms\n",
      "Speed: 3.1ms preprocess, 82.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6 bottles, 1 refrigerator, 71.4ms\n",
      "Speed: 1.5ms preprocess, 71.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8 bottles, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 cup, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 72.4ms\n",
      "Speed: 1.6ms preprocess, 72.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 cup, 1 refrigerator, 67.4ms\n",
      "Speed: 1.7ms preprocess, 67.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 cup, 1 refrigerator, 69.5ms\n",
      "Speed: 1.7ms preprocess, 69.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 cup, 1 refrigerator, 76.7ms\n",
      "Speed: 1.7ms preprocess, 76.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 87.7ms\n",
      "Speed: 1.5ms preprocess, 87.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 cup, 1 refrigerator, 65.8ms\n",
      "Speed: 2.1ms preprocess, 65.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 cup, 1 refrigerator, 66.8ms\n",
      "Speed: 2.0ms preprocess, 66.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 refrigerator, 72.4ms\n",
      "Speed: 1.6ms preprocess, 72.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 70.0ms\n",
      "Speed: 1.7ms preprocess, 70.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 62.5ms\n",
      "Speed: 1.6ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 63.4ms\n",
      "Speed: 2.0ms preprocess, 63.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 1 refrigerator, 1 book, 63.0ms\n",
      "Speed: 1.6ms preprocess, 63.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 bottles, 1 refrigerator, 1 book, 60.9ms\n",
      "Speed: 1.9ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 bottles, 1 refrigerator, 1 book, 57.2ms\n",
      "Speed: 2.0ms preprocess, 57.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 1 refrigerator, 1 book, 67.0ms\n",
      "Speed: 2.3ms preprocess, 67.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 1 book, 174.8ms\n",
      "Speed: 3.0ms preprocess, 174.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 22 bottles, 75.8ms\n",
      "Speed: 1.5ms preprocess, 75.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 bottles, 63.9ms\n",
      "Speed: 1.8ms preprocess, 63.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 63.5ms\n",
      "Speed: 1.6ms preprocess, 63.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 61.1ms\n",
      "Speed: 1.4ms preprocess, 61.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 59.9ms\n",
      "Speed: 1.6ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 1 tv, 63.3ms\n",
      "Speed: 1.3ms preprocess, 63.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 bottles, 1 tv, 62.3ms\n",
      "Speed: 2.2ms preprocess, 62.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 1 tv, 60.9ms\n",
      "Speed: 1.8ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 tv, 76.9ms\n",
      "Speed: 1.6ms preprocess, 76.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 bottles, 65.6ms\n",
      "Speed: 1.5ms preprocess, 65.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 68.8ms\n",
      "Speed: 2.8ms preprocess, 68.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 cup, 1 tv, 58.6ms\n",
      "Speed: 1.4ms preprocess, 58.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 cup, 1 tv, 67.0ms\n",
      "Speed: 1.4ms preprocess, 67.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 tv, 63.7ms\n",
      "Speed: 1.3ms preprocess, 63.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 59.6ms\n",
      "Speed: 1.4ms preprocess, 59.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21 bottles, 1 cup, 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 62.4ms\n",
      "Speed: 1.5ms preprocess, 62.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 63.4ms\n",
      "Speed: 1.7ms preprocess, 63.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 141.5ms\n",
      "Speed: 7.7ms preprocess, 141.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 78.2ms\n",
      "Speed: 2.3ms preprocess, 78.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 1 refrigerator, 89.9ms\n",
      "Speed: 1.5ms preprocess, 89.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21 bottles, 1 refrigerator, 64.1ms\n",
      "Speed: 1.6ms preprocess, 64.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 2 refrigerators, 63.6ms\n",
      "Speed: 1.5ms preprocess, 63.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 64.7ms\n",
      "Speed: 1.9ms preprocess, 64.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 61.3ms\n",
      "Speed: 1.9ms preprocess, 61.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 63.0ms\n",
      "Speed: 1.4ms preprocess, 63.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 bowl, 59.9ms\n",
      "Speed: 2.3ms preprocess, 59.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 refrigerator, 64.9ms\n",
      "Speed: 1.9ms preprocess, 64.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 bowl, 1 refrigerator, 92.2ms\n",
      "Speed: 3.9ms preprocess, 92.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 63.6ms\n",
      "Speed: 1.4ms preprocess, 63.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 63.2ms\n",
      "Speed: 1.6ms preprocess, 63.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 63.4ms\n",
      "Speed: 1.5ms preprocess, 63.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 61.4ms\n",
      "Speed: 1.5ms preprocess, 61.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 60.2ms\n",
      "Speed: 1.5ms preprocess, 60.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 bottles, 60.7ms\n",
      "Speed: 1.6ms preprocess, 60.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 2 refrigerators, 94.1ms\n",
      "Speed: 2.6ms preprocess, 94.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 2 refrigerators, 98.5ms\n",
      "Speed: 1.5ms preprocess, 98.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 2 refrigerators, 129.1ms\n",
      "Speed: 2.9ms preprocess, 129.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 84.6ms\n",
      "Speed: 3.5ms preprocess, 84.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 67.7ms\n",
      "Speed: 1.4ms preprocess, 67.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 refrigerator, 72.6ms\n",
      "Speed: 2.0ms preprocess, 72.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 cup, 1 refrigerator, 68.3ms\n",
      "Speed: 1.6ms preprocess, 68.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 69.0ms\n",
      "Speed: 2.0ms preprocess, 69.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 66.8ms\n",
      "Speed: 1.8ms preprocess, 66.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 69.0ms\n",
      "Speed: 2.2ms preprocess, 69.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 65.4ms\n",
      "Speed: 2.9ms preprocess, 65.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 64.9ms\n",
      "Speed: 1.4ms preprocess, 64.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9 bottles, 2 refrigerators, 62.0ms\n",
      "Speed: 1.4ms preprocess, 62.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 2 refrigerators, 61.3ms\n",
      "Speed: 1.4ms preprocess, 61.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 62.8ms\n",
      "Speed: 1.3ms preprocess, 62.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 63.4ms\n",
      "Speed: 1.7ms preprocess, 63.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 64.2ms\n",
      "Speed: 1.3ms preprocess, 64.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 70.6ms\n",
      "Speed: 1.8ms preprocess, 70.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 72.3ms\n",
      "Speed: 3.1ms preprocess, 72.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 refrigerator, 66.1ms\n",
      "Speed: 1.7ms preprocess, 66.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 2 refrigerators, 68.0ms\n",
      "Speed: 1.5ms preprocess, 68.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 2 refrigerators, 68.2ms\n",
      "Speed: 1.4ms preprocess, 68.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 2 refrigerators, 134.5ms\n",
      "Speed: 1.5ms preprocess, 134.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 2 refrigerators, 107.9ms\n",
      "Speed: 3.5ms preprocess, 107.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 2 refrigerators, 78.2ms\n",
      "Speed: 2.0ms preprocess, 78.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 2 refrigerators, 65.4ms\n",
      "Speed: 1.3ms preprocess, 65.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 2 refrigerators, 63.4ms\n",
      "Speed: 1.4ms preprocess, 63.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 2 refrigerators, 75.7ms\n",
      "Speed: 2.1ms preprocess, 75.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 69.7ms\n",
      "Speed: 1.7ms preprocess, 69.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 65.7ms\n",
      "Speed: 1.5ms preprocess, 65.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 72.5ms\n",
      "Speed: 1.6ms preprocess, 72.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 73.9ms\n",
      "Speed: 2.4ms preprocess, 73.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 refrigerator, 80.0ms\n",
      "Speed: 1.8ms preprocess, 80.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 67.3ms\n",
      "Speed: 1.7ms preprocess, 67.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 refrigerator, 71.6ms\n",
      "Speed: 1.7ms preprocess, 71.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 73.5ms\n",
      "Speed: 1.5ms preprocess, 73.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 69.2ms\n",
      "Speed: 1.7ms preprocess, 69.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 72.9ms\n",
      "Speed: 1.8ms preprocess, 72.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 70.4ms\n",
      "Speed: 1.7ms preprocess, 70.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 73.4ms\n",
      "Speed: 1.4ms preprocess, 73.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 79.5ms\n",
      "Speed: 1.7ms preprocess, 79.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 130.3ms\n",
      "Speed: 2.0ms preprocess, 130.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 108.1ms\n",
      "Speed: 2.7ms preprocess, 108.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 85.3ms\n",
      "Speed: 2.4ms preprocess, 85.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 61.1ms\n",
      "Speed: 1.5ms preprocess, 61.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 2 refrigerators, 68.4ms\n",
      "Speed: 1.4ms preprocess, 68.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 74.6ms\n",
      "Speed: 1.9ms preprocess, 74.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 2 refrigerators, 89.0ms\n",
      "Speed: 2.5ms preprocess, 89.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 77.8ms\n",
      "Speed: 2.5ms preprocess, 77.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 2 refrigerators, 99.6ms\n",
      "Speed: 1.9ms preprocess, 99.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 72.1ms\n",
      "Speed: 1.7ms preprocess, 72.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 67.1ms\n",
      "Speed: 1.4ms preprocess, 67.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 67.9ms\n",
      "Speed: 1.7ms preprocess, 67.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 66.1ms\n",
      "Speed: 1.9ms preprocess, 66.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 63.1ms\n",
      "Speed: 2.0ms preprocess, 63.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 65.8ms\n",
      "Speed: 1.6ms preprocess, 65.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 65.8ms\n",
      "Speed: 1.8ms preprocess, 65.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 2 refrigerators, 71.4ms\n",
      "Speed: 1.8ms preprocess, 71.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 83.6ms\n",
      "Speed: 1.9ms preprocess, 83.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 2 refrigerators, 70.9ms\n",
      "Speed: 1.8ms preprocess, 70.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 bowl, 1 refrigerator, 69.5ms\n",
      "Speed: 2.1ms preprocess, 69.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 2 refrigerators, 88.4ms\n",
      "Speed: 1.6ms preprocess, 88.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 2 refrigerators, 140.2ms\n",
      "Speed: 2.3ms preprocess, 140.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 2 refrigerators, 84.5ms\n",
      "Speed: 2.1ms preprocess, 84.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 2 refrigerators, 67.4ms\n",
      "Speed: 1.6ms preprocess, 67.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 68.2ms\n",
      "Speed: 2.0ms preprocess, 68.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 64.9ms\n",
      "Speed: 1.6ms preprocess, 64.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 78.1ms\n",
      "Speed: 1.7ms preprocess, 78.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 2 refrigerators, 76.1ms\n",
      "Speed: 2.2ms preprocess, 76.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 71.2ms\n",
      "Speed: 2.0ms preprocess, 71.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 2 refrigerators, 69.4ms\n",
      "Speed: 1.8ms preprocess, 69.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 71.2ms\n",
      "Speed: 1.7ms preprocess, 71.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 68.2ms\n",
      "Speed: 1.7ms preprocess, 68.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 67.3ms\n",
      "Speed: 1.8ms preprocess, 67.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 69.6ms\n",
      "Speed: 1.7ms preprocess, 69.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 72.6ms\n",
      "Speed: 1.9ms preprocess, 72.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 84.2ms\n",
      "Speed: 1.8ms preprocess, 84.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 74.4ms\n",
      "Speed: 2.0ms preprocess, 74.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8 bottles, 2 refrigerators, 70.7ms\n",
      "Speed: 1.6ms preprocess, 70.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8 bottles, 1 refrigerator, 72.2ms\n",
      "Speed: 1.8ms preprocess, 72.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8 bottles, 1 refrigerator, 67.5ms\n",
      "Speed: 1.9ms preprocess, 67.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7 bottles, 1 refrigerator, 166.8ms\n",
      "Speed: 1.8ms preprocess, 166.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6 bottles, 1 refrigerator, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6 bottles, 1 refrigerator, 69.5ms\n",
      "Speed: 1.5ms preprocess, 69.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 78.6ms\n",
      "Speed: 1.8ms preprocess, 78.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8 bottles, 1 refrigerator, 73.2ms\n",
      "Speed: 1.7ms preprocess, 73.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 2 refrigerators, 71.5ms\n",
      "Speed: 2.1ms preprocess, 71.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 73.1ms\n",
      "Speed: 1.6ms preprocess, 73.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 73.4ms\n",
      "Speed: 1.9ms preprocess, 73.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 66.8ms\n",
      "Speed: 1.5ms preprocess, 66.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 72.1ms\n",
      "Speed: 1.4ms preprocess, 72.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 2 refrigerators, 66.7ms\n",
      "Speed: 1.9ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 64.9ms\n",
      "Speed: 1.9ms preprocess, 64.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 74.8ms\n",
      "Speed: 2.2ms preprocess, 74.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 71.2ms\n",
      "Speed: 1.4ms preprocess, 71.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 71.9ms\n",
      "Speed: 1.6ms preprocess, 71.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 68.5ms\n",
      "Speed: 2.0ms preprocess, 68.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 66.6ms\n",
      "Speed: 1.4ms preprocess, 66.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 67.2ms\n",
      "Speed: 1.4ms preprocess, 67.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 89.8ms\n",
      "Speed: 2.1ms preprocess, 89.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 126.9ms\n",
      "Speed: 3.3ms preprocess, 126.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 97.4ms\n",
      "Speed: 3.3ms preprocess, 97.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 66.4ms\n",
      "Speed: 1.5ms preprocess, 66.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 68.3ms\n",
      "Speed: 2.2ms preprocess, 68.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 72.2ms\n",
      "Speed: 1.5ms preprocess, 72.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 69.0ms\n",
      "Speed: 1.5ms preprocess, 69.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 65.7ms\n",
      "Speed: 1.4ms preprocess, 65.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 75.8ms\n",
      "Speed: 1.8ms preprocess, 75.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 72.6ms\n",
      "Speed: 1.8ms preprocess, 72.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 66.8ms\n",
      "Speed: 1.7ms preprocess, 66.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 69.5ms\n",
      "Speed: 2.1ms preprocess, 69.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 84.8ms\n",
      "Speed: 1.5ms preprocess, 84.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 74.4ms\n",
      "Speed: 2.5ms preprocess, 74.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 65.4ms\n",
      "Speed: 2.0ms preprocess, 65.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 63.8ms\n",
      "Speed: 1.7ms preprocess, 63.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 70.6ms\n",
      "Speed: 1.9ms preprocess, 70.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 73.1ms\n",
      "Speed: 1.7ms preprocess, 73.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 73.3ms\n",
      "Speed: 2.2ms preprocess, 73.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 71.3ms\n",
      "Speed: 1.8ms preprocess, 71.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 135.0ms\n",
      "Speed: 1.7ms preprocess, 135.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 105.0ms\n",
      "Speed: 2.5ms preprocess, 105.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 89.2ms\n",
      "Speed: 1.6ms preprocess, 89.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 70.2ms\n",
      "Speed: 2.7ms preprocess, 70.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 66.1ms\n",
      "Speed: 1.4ms preprocess, 66.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 57.8ms\n",
      "Speed: 1.4ms preprocess, 57.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 66.3ms\n",
      "Speed: 1.5ms preprocess, 66.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 71.1ms\n",
      "Speed: 1.5ms preprocess, 71.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10 bottles, 1 refrigerator, 64.2ms\n",
      "Speed: 1.8ms preprocess, 64.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 64.7ms\n",
      "Speed: 1.5ms preprocess, 64.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 bottles, 1 refrigerator, 86.1ms\n",
      "Speed: 2.9ms preprocess, 86.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 66.1ms\n",
      "Speed: 1.6ms preprocess, 66.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 65.5ms\n",
      "Speed: 1.5ms preprocess, 65.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 63.0ms\n",
      "Speed: 2.2ms preprocess, 63.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 60.9ms\n",
      "Speed: 1.5ms preprocess, 60.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 65.0ms\n",
      "Speed: 1.9ms preprocess, 65.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 72.2ms\n",
      "Speed: 2.1ms preprocess, 72.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 69.5ms\n",
      "Speed: 1.8ms preprocess, 69.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 85.7ms\n",
      "Speed: 1.6ms preprocess, 85.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 64.4ms\n",
      "Speed: 1.9ms preprocess, 64.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 72.8ms\n",
      "Speed: 2.1ms preprocess, 72.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 88.5ms\n",
      "Speed: 1.8ms preprocess, 88.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 108.9ms\n",
      "Speed: 3.3ms preprocess, 108.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 80.4ms\n",
      "Speed: 1.7ms preprocess, 80.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 79.2ms\n",
      "Speed: 2.7ms preprocess, 79.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 77.3ms\n",
      "Speed: 1.9ms preprocess, 77.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 74.7ms\n",
      "Speed: 2.1ms preprocess, 74.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 70.0ms\n",
      "Speed: 1.7ms preprocess, 70.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 74.5ms\n",
      "Speed: 1.6ms preprocess, 74.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 78.0ms\n",
      "Speed: 1.8ms preprocess, 78.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 94.4ms\n",
      "Speed: 3.0ms preprocess, 94.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 69.9ms\n",
      "Speed: 1.4ms preprocess, 69.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 69.9ms\n",
      "Speed: 1.7ms preprocess, 69.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 64.8ms\n",
      "Speed: 1.6ms preprocess, 64.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 71.3ms\n",
      "Speed: 2.0ms preprocess, 71.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 71.7ms\n",
      "Speed: 1.7ms preprocess, 71.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 1 refrigerator, 66.2ms\n",
      "Speed: 1.7ms preprocess, 66.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19 bottles, 1 refrigerator, 198.4ms\n",
      "Speed: 2.2ms preprocess, 198.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 bottles, 1 refrigerator, 99.6ms\n",
      "Speed: 4.1ms preprocess, 99.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 73.9ms\n",
      "Speed: 1.9ms preprocess, 73.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 75.6ms\n",
      "Speed: 2.3ms preprocess, 75.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 refrigerator, 78.8ms\n",
      "Speed: 1.8ms preprocess, 78.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 bottles, 1 refrigerator, 85.4ms\n",
      "Speed: 2.0ms preprocess, 85.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 82.3ms\n",
      "Speed: 2.2ms preprocess, 82.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 86.9ms\n",
      "Speed: 2.0ms preprocess, 86.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 83.3ms\n",
      "Speed: 1.7ms preprocess, 83.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 72.1ms\n",
      "Speed: 2.1ms preprocess, 72.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 74.7ms\n",
      "Speed: 2.0ms preprocess, 74.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 bottles, 1 refrigerator, 63.8ms\n",
      "Speed: 1.3ms preprocess, 63.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 63.6ms\n",
      "Speed: 1.6ms preprocess, 63.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 bottles, 1 refrigerator, 61.0ms\n",
      "Speed: 1.8ms preprocess, 61.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 89.9ms\n",
      "Speed: 2.0ms preprocess, 89.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 128.3ms\n",
      "Speed: 2.5ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 90.2ms\n",
      "Speed: 3.2ms preprocess, 90.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 69.3ms\n",
      "Speed: 1.6ms preprocess, 69.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 65.3ms\n",
      "Speed: 1.5ms preprocess, 65.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 63.0ms\n",
      "Speed: 1.4ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 65.7ms\n",
      "Speed: 2.2ms preprocess, 65.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 bottles, 1 refrigerator, 64.2ms\n",
      "Speed: 1.3ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 1 refrigerator, 60.2ms\n",
      "Speed: 1.4ms preprocess, 60.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 bottles, 1 refrigerator, 63.2ms\n",
      "Speed: 1.4ms preprocess, 63.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 bottles, 62.3ms\n",
      "Speed: 1.7ms preprocess, 62.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \n\u001b[1;32m---> 17\u001b[0m results \u001b[38;5;241m=\u001b[39m model(frame)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     21\u001b[0m     frame \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mplot()  \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:182\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    155\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    156\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:550\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:214\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:323\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 323\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:171\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    167\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    170\u001b[0m )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:571\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 571\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:138\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:159\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 159\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    160\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:91\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:432\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2379\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   2380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  \n",
    "\n",
    "#video path\n",
    "video_path = \"A Day in Our Indian Grocery Store.mp4\"  \n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  \n",
    "\n",
    "   \n",
    "    results = model(frame)\n",
    "\n",
    "   \n",
    "    for result in results:\n",
    "        frame = result.plot()  \n",
    "\n",
    "    cv2.imshow(\"YOLOv8 Object Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffb666a-259f-4dcc-bae6-63287bda7175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 7 persons, 2 trucks, 3 cows, 2 umbrellas, 89.9ms\n",
      "Speed: 1.9ms preprocess, 89.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 cow, 2 umbrellas, 103.4ms\n",
      "Speed: 2.4ms preprocess, 103.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 2 umbrellas, 129.1ms\n",
      "Speed: 2.2ms preprocess, 129.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 trucks, 2 umbrellas, 101.2ms\n",
      "Speed: 2.9ms preprocess, 101.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 2 umbrellas, 93.6ms\n",
      "Speed: 2.0ms preprocess, 93.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 97.6ms\n",
      "Speed: 2.1ms preprocess, 97.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 86.4ms\n",
      "Speed: 2.2ms preprocess, 86.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 1 umbrella, 73.1ms\n",
      "Speed: 1.6ms preprocess, 73.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 1 umbrella, 76.5ms\n",
      "Speed: 1.9ms preprocess, 76.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 1 umbrella, 77.9ms\n",
      "Speed: 1.7ms preprocess, 77.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 trucks, 2 cows, 1 umbrella, 73.2ms\n",
      "Speed: 1.5ms preprocess, 73.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 1 umbrella, 77.9ms\n",
      "Speed: 1.8ms preprocess, 77.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 2 trucks, 1 cow, 3 umbrellas, 93.0ms\n",
      "Speed: 2.3ms preprocess, 93.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 trucks, 1 cow, 3 umbrellas, 71.9ms\n",
      "Speed: 2.0ms preprocess, 71.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 cow, 3 umbrellas, 74.4ms\n",
      "Speed: 1.7ms preprocess, 74.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 car, 2 trucks, 3 umbrellas, 76.9ms\n",
      "Speed: 2.3ms preprocess, 76.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 trucks, 3 umbrellas, 92.3ms\n",
      "Speed: 2.4ms preprocess, 92.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 3 umbrellas, 85.1ms\n",
      "Speed: 2.4ms preprocess, 85.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 trucks, 4 umbrellas, 78.7ms\n",
      "Speed: 1.9ms preprocess, 78.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 trucks, 4 umbrellas, 91.9ms\n",
      "Speed: 2.1ms preprocess, 91.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 trucks, 3 cows, 3 umbrellas, 98.0ms\n",
      "Speed: 2.1ms preprocess, 98.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 car, 2 trucks, 112.1ms\n",
      "Speed: 3.1ms preprocess, 112.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bus, 2 trucks, 1 umbrella, 93.9ms\n",
      "Speed: 2.6ms preprocess, 93.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 4 cows, 1 umbrella, 92.7ms\n",
      "Speed: 3.1ms preprocess, 92.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 car, 2 trucks, 1 umbrella, 99.7ms\n",
      "Speed: 1.8ms preprocess, 99.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 cow, 1 umbrella, 112.2ms\n",
      "Speed: 2.5ms preprocess, 112.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 bus, 2 trucks, 2 cows, 2 umbrellas, 279.7ms\n",
      "Speed: 3.6ms preprocess, 279.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 3 cows, 107.8ms\n",
      "Speed: 3.0ms preprocess, 107.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 2 trucks, 1 cow, 133.1ms\n",
      "Speed: 2.4ms preprocess, 133.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 2 trucks, 1 cow, 1 umbrella, 105.0ms\n",
      "Speed: 2.5ms preprocess, 105.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 2 trucks, 1 dog, 2 umbrellas, 119.3ms\n",
      "Speed: 2.6ms preprocess, 119.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 trucks, 106.6ms\n",
      "Speed: 3.2ms preprocess, 106.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 buss, 3 trucks, 1 dog, 103.8ms\n",
      "Speed: 2.9ms preprocess, 103.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bus, 2 trucks, 128.3ms\n",
      "Speed: 3.4ms preprocess, 128.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 92.8ms\n",
      "Speed: 2.8ms preprocess, 92.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 2 trucks, 1 dog, 1 frisbee, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 2 trucks, 1 dog, 1 frisbee, 87.0ms\n",
      "Speed: 2.7ms preprocess, 87.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 buss, 1 truck, 1 dog, 112.1ms\n",
      "Speed: 2.5ms preprocess, 112.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 85.1ms\n",
      "Speed: 2.7ms preprocess, 85.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 truck, 1 dog, 1 frisbee, 78.9ms\n",
      "Speed: 2.7ms preprocess, 78.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 1 dog, 1 frisbee, 81.8ms\n",
      "Speed: 1.8ms preprocess, 81.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 buss, 1 truck, 1 dog, 110.8ms\n",
      "Speed: 2.4ms preprocess, 110.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 buss, 1 dog, 1 umbrella, 111.1ms\n",
      "Speed: 3.7ms preprocess, 111.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 truck, 1 dog, 1 umbrella, 96.3ms\n",
      "Speed: 2.3ms preprocess, 96.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 buss, 1 dog, 1 cow, 103.8ms\n",
      "Speed: 2.8ms preprocess, 103.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 dog, 1 horse, 1 umbrella, 118.3ms\n",
      "Speed: 4.0ms preprocess, 118.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 truck, 1 dog, 1 horse, 1 umbrella, 117.5ms\n",
      "Speed: 4.9ms preprocess, 117.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 horse, 1 umbrella, 116.3ms\n",
      "Speed: 3.4ms preprocess, 116.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 bus, 1 truck, 1 dog, 1 cow, 2 umbrellas, 89.9ms\n",
      "Speed: 2.8ms preprocess, 89.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 truck, 1 dog, 1 horse, 1 cow, 1 umbrella, 85.6ms\n",
      "Speed: 2.3ms preprocess, 85.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 bus, 1 truck, 1 horse, 1 umbrella, 86.8ms\n",
      "Speed: 2.2ms preprocess, 86.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 truck, 1 horse, 1 cow, 1 umbrella, 1 frisbee, 80.4ms\n",
      "Speed: 2.1ms preprocess, 80.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 cow, 1 umbrella, 86.5ms\n",
      "Speed: 1.8ms preprocess, 86.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 1 umbrella, 1 frisbee, 112.7ms\n",
      "Speed: 2.2ms preprocess, 112.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 1 frisbee, 116.5ms\n",
      "Speed: 3.0ms preprocess, 116.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 1 truck, 1 dog, 1 cow, 1 frisbee, 103.0ms\n",
      "Speed: 3.3ms preprocess, 103.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 frisbee, 78.9ms\n",
      "Speed: 2.1ms preprocess, 78.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 truck, 1 dog, 1 cow, 1 frisbee, 86.6ms\n",
      "Speed: 2.3ms preprocess, 86.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 truck, 1 dog, 1 cow, 1 frisbee, 118.1ms\n",
      "Speed: 2.8ms preprocess, 118.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 umbrella, 1 frisbee, 148.8ms\n",
      "Speed: 4.5ms preprocess, 148.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 handbag, 1 frisbee, 142.3ms\n",
      "Speed: 3.1ms preprocess, 142.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 handbag, 128.5ms\n",
      "Speed: 2.7ms preprocess, 128.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 car, 1 bus, 1 dog, 1 cow, 1 handbag, 105.0ms\n",
      "Speed: 3.1ms preprocess, 105.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 dog, 1 cow, 1 handbag, 1 frisbee, 124.0ms\n",
      "Speed: 2.3ms preprocess, 124.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 dog, 1 cow, 1 handbag, 94.4ms\n",
      "Speed: 2.8ms preprocess, 94.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 dog, 1 cow, 1 umbrella, 97.5ms\n",
      "Speed: 2.3ms preprocess, 97.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 2 umbrellas, 89.1ms\n",
      "Speed: 2.2ms preprocess, 89.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 truck, 1 dog, 1 cow, 93.5ms\n",
      "Speed: 2.3ms preprocess, 93.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 89.0ms\n",
      "Speed: 2.6ms preprocess, 89.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 dog, 1 cow, 88.9ms\n",
      "Speed: 2.4ms preprocess, 88.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 cow, 92.3ms\n",
      "Speed: 2.3ms preprocess, 92.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 bus, 2 trucks, 1 cow, 87.6ms\n",
      "Speed: 2.4ms preprocess, 87.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 cow, 97.4ms\n",
      "Speed: 2.3ms preprocess, 97.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 bus, 1 truck, 1 cow, 101.6ms\n",
      "Speed: 3.3ms preprocess, 101.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 cow, 91.3ms\n",
      "Speed: 3.2ms preprocess, 91.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 bus, 2 trucks, 1 dog, 1 cow, 100.1ms\n",
      "Speed: 2.5ms preprocess, 100.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 3 trucks, 1 dog, 99.9ms\n",
      "Speed: 2.5ms preprocess, 99.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 trucks, 1 dog, 110.6ms\n",
      "Speed: 2.2ms preprocess, 110.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 1 dog, 106.1ms\n",
      "Speed: 2.2ms preprocess, 106.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 1 dog, 111.5ms\n",
      "Speed: 2.4ms preprocess, 111.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 1 dog, 1 backpack, 101.1ms\n",
      "Speed: 2.3ms preprocess, 101.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 3 trucks, 1 dog, 1 handbag, 114.9ms\n",
      "Speed: 2.4ms preprocess, 114.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# End of video\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m results \u001b[38;5;241m=\u001b[39m model(frame)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mboxes:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:182\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    155\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    156\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:550\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:214\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:323\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 323\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:171\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    167\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    170\u001b[0m )\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:571\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 571\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:138\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:159\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 159\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    160\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:683\u001b[0m, in \u001b[0;36mConcat.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    674\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;124;03m    Concatenate input tensors along specified dimension.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Concatenated tensor.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "video_path =  \"A Day in Our Indian Grocery Store.mp4\"  \n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "detected_classes = set()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # End of video\n",
    "\n",
    "  \n",
    "    results = model(frame)\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls[0]) \n",
    "            class_name = model.names[class_id] \n",
    "            detected_classes.add(class_name)  \n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Print list of detected classes\n",
    "print(\"Detected object classes:\", list(detected_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee66e5-5e53-4978-9e22-d08c23e37a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
